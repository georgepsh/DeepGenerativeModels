{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"d5d94463-e638-4acd-8a16-ad433148a12e"},"cells":[{"cell_type":"code","source":"from cloud_ml.storage.api import Storage\n\n# To retrieve client secret:\n# 1. Go to link: https://developers.google.com/drive/api/v3/quickstart/python\n# 2. Press \"Enable the drive API\"\n# 3. Choose \"TVs and limited input devices\"\nclient_secret = {}\n\n# downloading contents of the remote file into the local one\ngdrive = Storage.gdrive(client_secret)\ngdrive_file_id = '123456789'\ndst_path = 'path/to/file.txt'\ngdrive.get(gdrive_file_id, dst_path)","metadata":{"cellId":"4umgnr27jvsnzupjh1lexo"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Важно:\n\nПожалуйста, поддерживайте ваш код в хорошем состоянии, пишите комментарии, убирайте бесполезные ячейки, пишите модели в специально отведенных модулях. Проверяющие могут **НА СВОЕ УСМОТРЕНИЕ** снижать баллы за:\n\n1. Говнокод\n2. Неэффективные решения\n3. Вермишель из ячеек в тетрадке\n4. Все остальное что им не понравилось\n","metadata":{"cellId":"332goi5wfwdfkd7h6jrbov"}},{"cell_type":"markdown","source":"## Важно 2 (0 - 0.15 балла):\n\nЗа использование логгеров типа wandb/comet/neptune и красивую сборку этой домашки в виде графиков/картинок в этих логгерах мы будем выдавать бонусные баллы.\n\n","metadata":{"cellId":"tmvblurre70vedn583pah"}},{"cell_type":"markdown","source":"## Важно 3:\n\nРешением домашки является архив с использованными тетрадками/модулями, а так же **.pdf файл** с отчетом по проделанной работе по каждому пункту задачи. \nВ нем необходимо описать какие эксперименты вы производили чтобы получить результат который вы получили, а так же обосновать почему вы решили использовать штуки которые вы использовали (например дополнительные лоссы для стабилизации, WGAN-GP, а не GAN/WGAN+clip)\n","metadata":{"cellId":"rmhyat4ix1js3a5tob11ie"}},{"cell_type":"code","source":"import numpy as np\nimport torchvision\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\nfrom tqdm.notebook import tqdm\nfrom IPython.display import clear_output\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"cellId":"h15p604032w187zzeeprtr","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"В этом домашнем задании мы будем работать с Celeba. Celeba - это уже известный вам датасет состоящий из фотографий селеб в их привычной местности:","metadata":{"cellId":"zfzgurg56cmm56a4v81kua"}},{"cell_type":"code","source":"transforms = torchvision.transforms.Compose([\n    torchvision.transforms.Resize((64, 64)),\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])","metadata":{"cellId":"pthf7yewkmddgvo2w0a86","trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"celeba = torchvision.datasets.CelebA('celeba', target_type='attr', transform=transforms, download=True)\nceleba_dataloader = torch.utils.data.DataLoader(celeba, 1, shuffle=True)","metadata":{"cellId":"mpdnfzn38ofz2obc5jby9","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e89b8c562d9f44549ccf1d244a640b9b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bdb6e3323fe487da7313537ac20e0d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac98432c68bc4207b1a6764af30cd046"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e196b6a507264526bd18cec8e25bc1de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddffad76fb9649c4b1de4291e96bc926"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1beb45fa08840bda3a991d5fe927054"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"error","ename":"BadZipFile","evalue":"File is not a zip file","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mBadZipFile\u001B[0m                                Traceback (most recent call last)","\u001B[0;32m<ipython-input-3-11bec0631c8f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mceleba\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCelebA\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'celeba'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'attr'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mceleba_dataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataLoader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mceleba\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m#\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/celeba.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, split, target_type, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_integrity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/celeba.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m             \u001B[0mdownload_file_from_google_drive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_folder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mzipfile\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_folder\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"img_align_celeba.zip\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m             \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextractall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbase_folder\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/zipfile.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001B[0m\n\u001B[1;32m   1256\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1257\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'r'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1258\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_RealGetContents\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1259\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mmode\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'w'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'x'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1260\u001B[0m                 \u001B[0;31m# set the modified flag so central directory gets written\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/zipfile.py\u001B[0m in \u001B[0;36m_RealGetContents\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1323\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mBadZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"File is not a zip file\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1324\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mendrec\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1325\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mBadZipFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"File is not a zip file\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1326\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdebug\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1327\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mendrec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mBadZipFile\u001B[0m: File is not a zip file"]}],"execution_count":3},{"cell_type":"code","source":"index2attr = {i:j for i, j in enumerate(celeba.attr_names)}","metadata":{"cellId":"tonzpbb1p59ai1xbsozbu","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nfor index, (image, attr) in enumerate(celeba):\n    if index >= 10: break\n    plt.subplot(10, 1, index+1)\n    plt.imshow((image.squeeze().permute(1, 2, 0) + 1) / 2)\n    plt.title(', '.join([index2attr[att_i] for att_i, att_val in enumerate(attr.view(-1)) if att_val == 1]))\n    plt.axis('off')\n\nplt.show()","metadata":{"cellId":"zg5o2wss1kxc6b710qnu"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"В этой домашней работе вам предлагается повторить результаты статьи StarGAN (https://arxiv.org/abs/1711.09020). \n\nОсновная часть домашнего задания - чтение статьи и улучшение результатов, поэтому обязательно прочитайте не только StarGAN, но и другие Image-to-Image GAN подходы того времени (17-18 год) \n","metadata":{"cellId":"zet7et1t8gd7nwv4uvuy3b"}},{"cell_type":"markdown","source":"## Задача 1 (0.4 балла):\n\nПовторить результаты StarGAN используя только CelebA\n\nчто это значит: в статье предлагается способ использовать несколько датасетов и выучивание аттрибутов уникальных для какого-то одного датасета. Мы не просим вас это делать, вам достаточно просто обучить StarGAN на CelebA","metadata":{"cellId":"l32zuc6bo2jpn95a18c4k"}},{"cell_type":"code","source":"from model import StarGAN\nfrom utils import permute_labels\n\nmodel = StarGAN()","metadata":{"cellId":"4m8c9m1gq3ud8rx9ky4r8s"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.train()\nfor image, label in tqdm(celeba_dataloader, leave=False, desc=f\"trainloop: {epoch}\"):\n    # YOUR CODE\n\nmodel.eval()\nfor ind, (image, label) in enumerate(celeba_val_dataloader): # batch = 1\n    if ind >= 10: break\n\n    # пример сравнения качества на глаз:\n    new_label = permute_labels(label)\n    plt.figure(figsize=(20, 10))\n    plt.subplot(1, 2, 1)\n    plt.imshow((image[0].permute(1, 2, 0) + 1) / 2)\n    plt.subplot(1, 2, 2)\n    fake_image = model.generate(image.to(device), new_label.to(device)).detach().cpu()[0]\n    plt.imshow((fake_image.permute(1, 2, 0) + 1) / 2)\n    plt.show()\n","metadata":{"cellId":"wpx0pndts7qrtd57p97u7o"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Важно 4: \n\nЕсли вы учите на колабе или на наших машинках, вероятнее всего что обучение будет очень долгим на картинках 256х256. Никто не мешает уменьшить разрешение, главное чтобы было видно что трансформации выучились\n\nЕще, кажется что не все аттрибуты селебы являются очень важными или достаточно представленными в датасете. Не запрещается убирать бесполезные аттрибуты (только обоснуйте почему так сделали в отчете)\n\nНе забывайте про аугментации\n\n## Важно 5: \n\nДа, мы знаем что в на гитхабе лежить готовый код на путорче для этой статьи. Проблема в том что он написал на torch 0.4, поэтому, если мы увидим что вы используете __старый__ код со старыми модулями, то мы:\n\n1. Будем неодобрительно смотреть\n2. За наглое списывание будем снимать баллы\n","metadata":{"cellId":"48zkv89n2h5ewyh841rjc"}},{"cell_type":"markdown","source":"## Задача 2 (0.2 балла): \n\nМерить качество на глаз - плохая идея. Подключите подсчет FID для каждой N эпохи, чтобы вы могли следить за прогрессом модели.\n\nСранение моделей между собой тоже возможно только по FID, поэтому трекайте его когда будете делать другие эксперименты","metadata":{"cellId":"66or6m3h0iwm8ddathkcs"}},{"cell_type":"markdown","source":"## Задача 3 (0.4 балла):\n\nЕсли вы будете дословно повторять архитектуру авторов статьи, вы сразу же увидите что обучение станет дико долгим и не очень стабильным. Возможно у вас получится предложить несколько улучшений, которые приведут к хорошему FID, к визуально лучшим результатам или к более стабильному обучению.\n\nВ этой задаче хочется чтобы вы попробовали улучшить результаты статьи используя либо то что уже знаете, либо что-то из релевантных статей по Im2Im современности","metadata":{"cellId":"xr7hcwjbzuqlqp3a4qs3u"}},{"cell_type":"markdown","source":"## Важно 6: \n\nКогда вы будете показывать визуальные трансформации которые делает ваш StarGAN, хорошей идеей будет сразу же зафиксировать набор картинок (очевидно из валидации) и набор трансформаций на которых вы будете показывать результаты. Например: 10 картинок разных людей на которых вы покажете Male-Female, Beard-noBeard, Old-Young трансформации","metadata":{"cellId":"uq3yrr0yp7gjug0825q"}},{"cell_type":"markdown","source":"## Важно 7 (0.15 балла): \n\nВыдам дополнительные баллы если у вас получится визуально красивая перекраска волос в разные цвета","metadata":{"cellId":"msts1cbr6r78g22vy1v1v"}}]}